{"cells":[{"cell_type":"markdown","metadata":{"id":"zje59_CLkH-h"},"source":["<b>[Python sample code: the single model (weak learner)] Kagawa et al. Predicting elevated natriuretic peptide in chest radiography: Emerging utilization gap for artificial intelligence. European Heart Journal - Imaging Methods and Practice, qyae064, https://doi.org/10.1093/ehjimp/qyae064</b><br>\n","<br>\n","The sample codes are utilized in Google Colab or Jupyter Notebook.\n","\n","version 1.0.2 July 04, 2024: model_0 available. with GRAD-CAM. non-squared image available."]},{"cell_type":"markdown","metadata":{"id":"IqfhlrlbkH-j"},"source":["1. If you utilize in Google Colab, mount Google Colab.\n","2. Install tensorflow_addons.\n","\n","In Google Colab or Jupyter Notebook, either click the arrow on the cell or select the cell and use the appropriate shortcut to execute it (Shift + Enter)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14415,"status":"ok","timestamp":1720061303446,"user":{"displayName":"Eisuke Kagawa","userId":"09263632618654374896"},"user_tz":-540},"id":"AfbFLdD_kH-j","outputId":"b5e45dd4-4824-4693-c228-e4789189a18b"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install tensorflow_addons"]},{"cell_type":"markdown","metadata":{"id":"p_nK8IMhkH-k"},"source":["2. Import libraries.<br>\n","Please ignore TFA warning.<br>"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7739,"status":"ok","timestamp":1720061313965,"user":{"displayName":"Eisuke Kagawa","userId":"09263632618654374896"},"user_tz":-540},"id":"8j9VbP_rkH-k","outputId":"0ce8f16e-2ab8-49d1-b0f6-d777a7c77fc7"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import math"]},{"cell_type":"markdown","metadata":{"id":"Ez6GS_NPkH-k"},"source":["3. Copy chest radiograms to image_file_path.<br>\n","4. Save 'model_0.h5' to model_path.<br>\n","Example:<br>\n","model_path = '/content/drive/MyDrive/model_0.h5'<br>\n","5. Define image files path.<br>\n","Example:<br>\n","image_file_path = '/content/drive/MyDrive/image_file.png'<br>"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1720061313965,"user":{"displayName":"Eisuke Kagawa","userId":"09263632618654374896"},"user_tz":-540},"id":"GEXLD8VhkH-k"},"outputs":[],"source":["'''\n","model_path = '/content/drive/MyDrive/model_0.h5'\n","image_file_path = '/content/drive/MyDrive/image_file.png'\n","'''\n","\n","model_path = 'C:/Users/egkag/Dropbox/GitHub_public_ekagawa007/Zenodo/BNP200models/model_0.h5'\n","#image_file_path = 'C:/Users/egkag/Dropbox/GitHub_public_ekagawa007/Zenodo/MichikoSakamoto91F20220517Cre373Hb115AHF1BNP1518_2.png'\n","#image_file_path = 'C:/Users/egkag/Dropbox/GitHub_public_ekagawa007/Zenodo/AtsukoSuzawa85F20220519Cre177Hb102BNP2296_resizedSq.png'\n","image_file_path = 'C:/Users/egkag/Dropbox/GitHub_public_ekagawa007/Zenodo/MichihisaUeda63M20220531Cre069Hb137BNP57.png'\n"]},{"cell_type":"markdown","metadata":{},"source":["6. Visualize image"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["BACKGROUND_COLOR = (0, 0, 0)     #black\n","\n","# for model_0\n","target_size = 224\n","MODEL_NEED_PREPROCESS_INPUT = True\n","MODEL_PREPROCESS_INPUT = tf.keras.applications.vgg16.preprocess_input\n","last_conv_layer_name = \"block5_conv3\"\n","HEATMAP_SIZE = (14, 14)\n","\n","def load_and_preprocess_image(path, target_size):   \n","    try:\n","        im = Image.open(path).convert(\"RGB\")\n","        width, height = im.size\n","        if width > height:\n","            result = Image.new(im.mode, (width, width), BACKGROUND_COLOR)\n","            result.paste(im, (0, (width - height) // 2))\n","        elif width < height:\n","            result = Image.new(im.mode, (height, height), BACKGROUND_COLOR)\n","            result.paste(im, ((height - width) // 2, 0))\n","        else:\n","            result = im\n","    except OSError as e:\n","        pass\n","\n","    result = result.resize((target_size, target_size))\n","    image_array = img_to_array(result)\n","\n","    return image_array\n","\n","image_array = load_and_preprocess_image(image_file_path, target_size)\n","print ('Shape of image: ', image_array.shape)\n","\n","custom_objects = {\"Addons>mish\": tfa.activations.mish}\n","model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n","#print (model.summary())\n","\n","plt. imshow(image_array.astype('uint8'))\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"eoLCDzEhkH-k"},"source":["7. Load model and predict<br>"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2807,"status":"ok","timestamp":1720061318731,"user":{"displayName":"Eisuke Kagawa","userId":"09263632618654374896"},"user_tz":-540},"id":"e-YAIyHYkH-l","outputId":"b9f75750-d975-45c5-eb67-1cd789c6c9ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 2s 2s/step\n","File:  C:/Users/egkag/Dropbox/GitHub_public_ekagawa007/Zenodo/MichihisaUeda63M20220531Cre069Hb137BNP57.png\n","Model:  C:/Users/egkag/Dropbox/GitHub_public_ekagawa007/Zenodo/BNP200models/model_0.h5\n","The provability of BNP >= 200 pg/mL (single model): 0.25471315\n"]}],"source":["img_array = np.expand_dims(image_array, axis=0)\n","preprocess_input = MODEL_PREPROCESS_INPUT\n","tmp_probs = model.predict(preprocess_input(img_array))\n","print('File: ', image_file_path)\n","print('Model: ', model_path)\n","print('The provability of BNP >= 200 pg/mL (single model):', tmp_probs[0][1])"]},{"cell_type":"markdown","metadata":{},"source":["8. Show featured map image"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()\n","\n","\n","if MODEL_NEED_PREPROCESS_INPUT == True:\n","    img_array = preprocess_input(img_array)\n","\n","model.layers[-1].activation = None\n","\n","heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n","\n","plt.matshow(heatmap)\n","plt.show()\n","\n","\n","def save_and_display_gradcam(img_path, heatmap, alpha=0.4):\n","    img = tf.keras.preprocessing.image.load_img(img_path)\n","    img = tf.keras.preprocessing.image.img_to_array(img)\n","\n","    # Rescale heatmap to a range 0-255\n","    heatmap = np.uint8(255 * heatmap)\n","\n","    jet = plt.colormaps[\"jet\"]\n","\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","\n","    # Create an image with RGB colorized heatmap\n","    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n","\n","    # Superimpose the heatmap on original image\n","    superimposed_img = jet_heatmap * alpha + img\n","    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n","\n","    # Save the superimposed image\n","    #superimposed_img.save(cam_path)\n","\n","    display(superimposed_img)\n","\n","save_and_display_gradcam(image_file_path, heatmap)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1x3BO0EYcZZYuMBDOOyXvSsDVtnvO9WWV","timestamp":1647529276850}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
